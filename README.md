# Trustworthy AI - Projet de Classification Faciale

## ğŸ“‹ Description du Projet

Projet d'Ã©thique en Intelligence Artificielle dÃ©veloppÃ© par une Ã©quipe de 3 Ã©tudiants. L'objectif est de construire un modÃ¨le d'IA intÃ©grant les caractÃ©ristiques d'un Trustworthy AI model avec :

- **Classification faciale** des 3 membres du groupe
- **Apprentissage fÃ©dÃ©rÃ©** pour la protection de la confidentialitÃ©
- **Techniques d'IA explicable** (LIME, SHAP, Grad-CAM)
- **SÃ©curitÃ© et confidentialitÃ©** des donnÃ©es

## ğŸ¯ Objectifs

1. EntraÃ®ner un modÃ¨le global avec Federated Learning
2. Appliquer des techniques d'Explainable AI
3. Garantir la protection de la confidentialitÃ© et sÃ©curitÃ©
4. Maximiser la prÃ©cision du modÃ¨le

## ğŸ—ï¸ Structure du Projet

```
trustworthy-ai/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Photos brutes des 3 membres
â”‚   â”‚   â”œâ”€â”€ member1/
â”‚   â”‚   â”œâ”€â”€ member2/
â”‚   â”‚   â””â”€â”€ member3/
â”‚   â”œâ”€â”€ processed/              # Images prÃ©processÃ©es
â”‚   â””â”€â”€ federated/             # DonnÃ©es distribuÃ©es pour FL
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   # PrÃ©paration des donnÃ©es
â”‚   â”‚   â””â”€â”€ data_loader.py     # Chargement des donnÃ©es
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cnn_model.py       # Architecture CNN
â”‚   â”‚   â”œâ”€â”€ federated_client.py# Client FL
â”‚   â”‚   â””â”€â”€ federated_server.py# Serveur FL
â”‚   â”œâ”€â”€ explainability/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lime_explainer.py  # LIME implementation
â”‚   â”‚   â”œâ”€â”€ shap_explainer.py  # SHAP implementation
â”‚   â”‚   â””â”€â”€ gradcam_explainer.py# Grad-CAM implementation
â”‚   â”œâ”€â”€ privacy/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ differential_privacy.py
â”‚   â”‚   â””â”€â”€ encryption.py      # Chiffrement des paramÃ¨tres
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py          # Configuration
â”‚       â”œâ”€â”€ metrics.py         # MÃ©triques d'Ã©valuation
â”‚       â””â”€â”€ visualization.py   # Visualisations
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â”œâ”€â”€ 03_federated_learning.ipynb
â”‚   â”œâ”€â”€ 04_explainability_analysis.ipynb
â”‚   â””â”€â”€ 05_privacy_evaluation.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_explainability.py
â”‚   â””â”€â”€ test_privacy.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ethics_report.md       # Rapport Ã©thique
â”‚   â”œâ”€â”€ model_documentation.md
â”‚   â””â”€â”€ privacy_analysis.md
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â”œâ”€â”€ federated_config.yaml
â”‚   â””â”€â”€ privacy_config.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ .gitignore
```

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Deep Learning**: TensorFlow/Keras, PyTorch
- **Federated Learning**: TensorFlow Federated (TFF)
- **Explainable AI**: LIME, SHAP, tf-explain
- **Privacy**: TensorFlow Privacy, PySyft
- **Data Science**: NumPy, Pandas, Scikit-learn
- **Visualization**: Matplotlib, Seaborn, Plotly

## ğŸ“¦ Installation

```bash
# Cloner le projet
git clone <repository-url>
cd trustworthy-ai

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸš€ Utilisation

### 1. PrÃ©paration des DonnÃ©es

```bash
python src/data/preprocessing.py
```

### 2. EntraÃ®nement FÃ©dÃ©rÃ©

```bash
python src/models/federated_server.py
```

### 3. Analyse d'ExplicabilitÃ©

```bash
jupyter notebook notebooks/04_explainability_analysis.ipynb
```

## ğŸ“Š CritÃ¨res d'Ã‰valuation

1. **PrÃ©cision des ModÃ¨les**: Confiance vs hasard
2. **Protection de la ConfidentialitÃ©**:
   - Division sÃ©curisÃ©e des donnÃ©es
   - Chiffrement des paramÃ¨tres
   - AgrÃ©gation sÃ©curisÃ©e
3. **ExplainabilitÃ©**: Application de techniques d'XAI
4. **Documentation Ã‰thique**: Rapport complet

## ğŸ‘¥ Ã‰quipe

- Membre 1: [Nom]
- Membre 2: [Nom]
- Membre 3: [Nom]

## ğŸ“… Timeline

- **Date de remise**: 20-11-2025
- **Type d'Ã©valuation**: Moyenne et Examen

## ğŸ“„ License

Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique pour le cours d'Ã©thique en IA.
