{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f4afc2",
   "metadata": {},
   "source": [
    "# ğŸ“Š Exploration des DonnÃ©es - Projet Trustworthy AI\n",
    "\n",
    "**Objectif**: Explorer et analyser les donnÃ©es d'images faciales des 3 membres du groupe pour prÃ©parer l'apprentissage fÃ©dÃ©rÃ©.\n",
    "\n",
    "## ğŸ¯ Contenu du notebook\n",
    "1. Chargement et configuration\n",
    "2. Exploration des dossiers de donnÃ©es\n",
    "3. Visualisation des images\n",
    "4. Analyse de la qualitÃ© des donnÃ©es\n",
    "5. Statistiques du dataset\n",
    "6. PrÃ©paration pour l'apprentissage fÃ©dÃ©rÃ©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104fcde",
   "metadata": {},
   "source": [
    "## 1. ğŸ“š Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63a82cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Configuration terminÃ©e!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "# Configuration\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Chemin des donnÃ©es\n",
    "DATA_PATH = \"../data/raw\"\n",
    "\n",
    "print(\"ğŸ”§ Configuration terminÃ©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef687b2",
   "metadata": {},
   "source": [
    "## 2. ğŸ” Exploration de la Structure des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data_structure(data_path):\n",
    "    \"\"\"Explore la structure des dossiers de donnÃ©es\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“ Structure du dossier de donnÃ©es:\")\n",
    "    print(f\"Chemin principal: {data_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"âŒ Le dossier de donnÃ©es n'existe pas!\")\n",
    "        print(\"ğŸ’¡ CrÃ©ez les dossiers et ajoutez vos photos:\")\n",
    "        print(\"   - data/raw/member1/\")\n",
    "        print(\"   - data/raw/member2/\")\n",
    "        print(\"   - data/raw/member3/\")\n",
    "        return None\n",
    "    \n",
    "    data_info = {}\n",
    "    \n",
    "    for member_folder in sorted(os.listdir(data_path)):\n",
    "        member_path = os.path.join(data_path, member_folder)\n",
    "        \n",
    "        if os.path.isdir(member_path) and member_folder.startswith('member'):\n",
    "            # Compter les images\n",
    "            image_files = [f for f in os.listdir(member_path) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            data_info[member_folder] = {\n",
    "                'path': member_path,\n",
    "                'num_images': len(image_files),\n",
    "                'image_files': image_files\n",
    "            }\n",
    "            \n",
    "            print(f\"ğŸ‘¤ {member_folder}: {len(image_files)} images\")\n",
    "    \n",
    "    total_images = sum([info['num_images'] for info in data_info.values()])\n",
    "    print(f\"\\nğŸ“Š Total: {total_images} images pour {len(data_info)} membres\")\n",
    "    \n",
    "    return data_info\n",
    "\n",
    "# Explorer la structure\n",
    "data_info = explore_data_structure(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1a7d9",
   "metadata": {},
   "source": [
    "## 3. ğŸ–¼ï¸ Visualisation des Ã‰chantillons d'Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde38277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(data_info, samples_per_member=3):\n",
    "    \"\"\"Affiche des Ã©chantillons d'images pour chaque membre\"\"\"\n",
    "    \n",
    "    if data_info is None:\n",
    "        print(\"âŒ Impossible d'afficher les images - donnÃ©es manquantes\")\n",
    "        return\n",
    "    \n",
    "    num_members = len(data_info)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_members, samples_per_member, \n",
    "                            figsize=(15, 5 * num_members))\n",
    "    \n",
    "    if num_members == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, (member_name, member_data) in enumerate(data_info.items()):\n",
    "        image_files = member_data['image_files']\n",
    "        \n",
    "        # SÃ©lectionner des Ã©chantillons alÃ©atoires\n",
    "        sample_files = np.random.choice(image_files, \n",
    "                                      min(samples_per_member, len(image_files)), \n",
    "                                      replace=False)\n",
    "        \n",
    "        for j, img_file in enumerate(sample_files):\n",
    "            img_path = os.path.join(member_data['path'], img_file)\n",
    "            \n",
    "            try:\n",
    "                # Charger et afficher l'image\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                axes[i, j].imshow(image)\n",
    "                axes[i, j].set_title(f\"{member_name}\\n{img_file}\", fontsize=10)\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "            except Exception as e:\n",
    "                axes[i, j].text(0.5, 0.5, f\"Erreur:\\n{img_file}\", \n",
    "                               ha='center', va='center', transform=axes[i, j].transAxes)\n",
    "                axes[i, j].axis('off')\n",
    "        \n",
    "        # Masquer les axes supplÃ©mentaires s'il y a moins d'images\n",
    "        for j in range(len(sample_files), samples_per_member):\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"ğŸ“¸ Ã‰chantillons d'Images par Membre\", fontsize=16, y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualiser les Ã©chantillons\n",
    "visualize_sample_images(data_info, samples_per_member=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b531150",
   "metadata": {},
   "source": [
    "## 4. ğŸ“ Analyse des Dimensions et QualitÃ© des Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6109944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(data_info):\n",
    "    \"\"\"Analyse les propriÃ©tÃ©s des images (dimensions, format, qualitÃ©)\"\"\"\n",
    "    \n",
    "    if data_info is None:\n",
    "        print(\"âŒ Impossible d'analyser - donnÃ©es manquantes\")\n",
    "        return None\n",
    "    \n",
    "    analysis_results = []\n",
    "    \n",
    "    print(\"ğŸ” Analyse des propriÃ©tÃ©s des images...\")\n",
    "    \n",
    "    for member_name, member_data in data_info.items():\n",
    "        print(f\"\\nğŸ‘¤ Analyse de {member_name}:\")\n",
    "        \n",
    "        for img_file in member_data['image_files']:\n",
    "            img_path = os.path.join(member_data['path'], img_file)\n",
    "            \n",
    "            try:\n",
    "                # Ouvrir avec PIL pour les mÃ©tadonnÃ©es\n",
    "                with Image.open(img_path) as img:\n",
    "                    width, height = img.size\n",
    "                    format_img = img.format\n",
    "                    mode = img.mode\n",
    "                \n",
    "                # Taille du fichier\n",
    "                file_size = os.path.getsize(img_path) / 1024  # KB\n",
    "                \n",
    "                analysis_results.append({\n",
    "                    'member': member_name,\n",
    "                    'filename': img_file,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'aspect_ratio': width / height,\n",
    "                    'format': format_img,\n",
    "                    'mode': mode,\n",
    "                    'file_size_kb': file_size,\n",
    "                    'resolution': width * height\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Erreur avec {img_file}: {e}\")\n",
    "    \n",
    "    if analysis_results:\n",
    "        df = pd.DataFrame(analysis_results)\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Analyser les propriÃ©tÃ©s\n",
    "df_analysis = analyze_image_properties(data_info)\n",
    "\n",
    "if df_analysis is not None:\n",
    "    print(\"\\nğŸ“Š RÃ©sumÃ© statistique:\")\n",
    "    print(df_analysis.groupby('member').agg({\n",
    "        'width': ['mean', 'std', 'min', 'max'],\n",
    "        'height': ['mean', 'std', 'min', 'max'],\n",
    "        'file_size_kb': ['mean', 'std', 'min', 'max'],\n",
    "        'aspect_ratio': ['mean', 'std']\n",
    "    }).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17655ae1",
   "metadata": {},
   "source": [
    "## 5. ğŸ“Š Visualisations Statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statistical_visualizations(df_analysis, data_info):\n",
    "    \"\"\"CrÃ©e des visualisations statistiques du dataset\"\"\"\n",
    "    \n",
    "    if df_analysis is None or data_info is None:\n",
    "        print(\"âŒ DonnÃ©es insuffisantes pour les visualisations\")\n",
    "        return\n",
    "    \n",
    "    # Configuration des couleurs\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "    \n",
    "    # 1. Distribution du nombre d'images par membre\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Subplot 1: Nombre d'images par membre\n",
    "    plt.subplot(2, 3, 1)\n",
    "    member_counts = df_analysis['member'].value_counts()\n",
    "    bars = plt.bar(member_counts.index, member_counts.values, color=colors)\n",
    "    plt.title('ğŸ“Š Nombre d\\'Images par Membre')\n",
    "    plt.ylabel('Nombre d\\'images')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, value in zip(bars, member_counts.values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                str(value), ha='center', va='bottom')\n",
    "    \n",
    "    # Subplot 2: Distribution des largeurs\n",
    "    plt.subplot(2, 3, 2)\n",
    "    for i, member in enumerate(df_analysis['member'].unique()):\n",
    "        member_data = df_analysis[df_analysis['member'] == member]\n",
    "        plt.hist(member_data['width'], alpha=0.7, label=member, \n",
    "                color=colors[i], bins=10)\n",
    "    plt.title('ğŸ“ Distribution des Largeurs')\n",
    "    plt.xlabel('Largeur (pixels)')\n",
    "    plt.ylabel('FrÃ©quence')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Subplot 3: Distribution des hauteurs\n",
    "    plt.subplot(2, 3, 3)\n",
    "    for i, member in enumerate(df_analysis['member'].unique()):\n",
    "        member_data = df_analysis[df_analysis['member'] == member]\n",
    "        plt.hist(member_data['height'], alpha=0.7, label=member, \n",
    "                color=colors[i], bins=10)\n",
    "    plt.title('ğŸ“ Distribution des Hauteurs')\n",
    "    plt.xlabel('Hauteur (pixels)')\n",
    "    plt.ylabel('FrÃ©quence')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Subplot 4: Ratio d'aspect\n",
    "    plt.subplot(2, 3, 4)\n",
    "    sns.boxplot(data=df_analysis, x='member', y='aspect_ratio', palette=colors)\n",
    "    plt.title('ğŸ“± Ratio d\\'Aspect par Membre')\n",
    "    plt.ylabel('Ratio (largeur/hauteur)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Subplot 5: Taille des fichiers\n",
    "    plt.subplot(2, 3, 5)\n",
    "    sns.boxplot(data=df_analysis, x='member', y='file_size_kb', palette=colors)\n",
    "    plt.title('ğŸ’¾ Taille des Fichiers par Membre')\n",
    "    plt.ylabel('Taille (KB)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Subplot 6: RÃ©solution totale\n",
    "    plt.subplot(2, 3, 6)\n",
    "    sns.scatterplot(data=df_analysis, x='width', y='height', \n",
    "                   hue='member', palette=colors, s=50)\n",
    "    plt.title('ğŸ¯ Largeur vs Hauteur')\n",
    "    plt.xlabel('Largeur (pixels)')\n",
    "    plt.ylabel('Hauteur (pixels)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Tableau de rÃ©sumÃ©\n",
    "    print(\"\\nğŸ“‹ RÃ©sumÃ© du Dataset:\")\n",
    "    summary_table = df_analysis.groupby('member').agg({\n",
    "        'filename': 'count',\n",
    "        'width': 'mean',\n",
    "        'height': 'mean',\n",
    "        'file_size_kb': 'mean',\n",
    "        'aspect_ratio': 'mean'\n",
    "    }).round(1)\n",
    "    \n",
    "    summary_table.columns = ['Nb Images', 'Largeur Moy.', 'Hauteur Moy.', 'Taille Moy. (KB)', 'Ratio Moy.']\n",
    "    print(summary_table)\n",
    "\n",
    "# CrÃ©er les visualisations\n",
    "create_statistical_visualizations(df_analysis, data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f671a",
   "metadata": {},
   "source": [
    "## 6. ğŸ”’ Analyse pour l'Apprentissage FÃ©dÃ©rÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_for_federated_learning(data_info, df_analysis):\n",
    "    \"\"\"Analyse la rÃ©partition des donnÃ©es pour l'apprentissage fÃ©dÃ©rÃ©\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”’ Analyse pour l'Apprentissage FÃ©dÃ©rÃ©\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if data_info is None:\n",
    "        print(\"âŒ DonnÃ©es manquantes\")\n",
    "        return\n",
    "    \n",
    "    total_images = sum([info['num_images'] for info in data_info.values()])\n",
    "    num_clients = len(data_info)\n",
    "    \n",
    "    print(f\"ğŸ“Š Configuration FÃ©dÃ©rÃ©e:\")\n",
    "    print(f\"   â€¢ Nombre de clients: {num_clients}\")\n",
    "    print(f\"   â€¢ Total d'images: {total_images}\")\n",
    "    print(f\"   â€¢ Moyenne par client: {total_images/num_clients:.1f} images\")\n",
    "    \n",
    "    # Distribution des donnÃ©es\n",
    "    print(f\"\\nğŸ‘¥ RÃ©partition par client:\")\n",
    "    for i, (member_name, member_data) in enumerate(data_info.items(), 1):\n",
    "        num_images = member_data['num_images']\n",
    "        percentage = (num_images / total_images) * 100\n",
    "        print(f\"   Client {i} ({member_name}): {num_images} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Recommandations pour l'apprentissage fÃ©dÃ©rÃ©\n",
    "    print(f\"\\nğŸ’¡ Recommandations:\")\n",
    "    \n",
    "    # VÃ©rifier l'Ã©quilibre des donnÃ©es\n",
    "    image_counts = [info['num_images'] for info in data_info.values()]\n",
    "    std_dev = np.std(image_counts)\n",
    "    mean_count = np.mean(image_counts)\n",
    "    cv = std_dev / mean_count  # Coefficient de variation\n",
    "    \n",
    "    if cv < 0.2:\n",
    "        print(\"   âœ… Distribution Ã©quilibrÃ©e des donnÃ©es\")\n",
    "    elif cv < 0.5:\n",
    "        print(\"   âš ï¸ Distribution moyennement Ã©quilibrÃ©e\")\n",
    "        print(\"   ğŸ’¡ ConsidÃ©rez l'augmentation des donnÃ©es pour les clients avec moins d'images\")\n",
    "    else:\n",
    "        print(\"   âŒ Distribution dÃ©sÃ©quilibrÃ©e\")\n",
    "        print(\"   ğŸ’¡ Recommandation forte: augmentation de donnÃ©es ou rÃ©Ã©quilibrage\")\n",
    "    \n",
    "    # Minimum recommandÃ©\n",
    "    min_images = min(image_counts)\n",
    "    if min_images < 10:\n",
    "        print(f\"   âš ï¸ Client avec seulement {min_images} images - minimum recommandÃ©: 20\")\n",
    "    elif min_images < 20:\n",
    "        print(f\"   âš ï¸ Minimum d'images acceptable mais bas ({min_images})\")\n",
    "    else:\n",
    "        print(f\"   âœ… Nombre d'images suffisant (min: {min_images})\")\n",
    "    \n",
    "    # StratÃ©gie d'entraÃ®nement\n",
    "    print(f\"\\nğŸ¯ StratÃ©gies recommandÃ©es:\")\n",
    "    print(f\"   â€¢ Taille de batch: 8-16 (donnÃ©es limitÃ©es)\")\n",
    "    print(f\"   â€¢ Augmentation de donnÃ©es: Fortement recommandÃ©e\")\n",
    "    print(f\"   â€¢ Rounds fÃ©dÃ©rÃ©s: 50-100\")\n",
    "    print(f\"   â€¢ Epochs locaux: 3-5 par round\")\n",
    "    \n",
    "    # ConfidentialitÃ©\n",
    "    print(f\"\\nğŸ”’ Aspects de confidentialitÃ©:\")\n",
    "    print(f\"   â€¢ DonnÃ©es sensibles: Images faciales identifiables\")\n",
    "    print(f\"   â€¢ Differential Privacy: RecommandÃ©e (Îµ=1.0)\")\n",
    "    print(f\"   â€¢ Secure Aggregation: Obligatoire\")\n",
    "    print(f\"   â€¢ Chiffrement des communications: TLS 1.3\")\n",
    "\n",
    "# Analyser pour l'apprentissage fÃ©dÃ©rÃ©\n",
    "analyze_for_federated_learning(data_info, df_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c8d9c",
   "metadata": {},
   "source": [
    "## 7. âœ… Checklist de PrÃ©paration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817bba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preparation_checklist(data_info, df_analysis):\n",
    "    \"\"\"CrÃ©e une checklist pour la prÃ©paration des donnÃ©es\"\"\"\n",
    "    \n",
    "    print(\"âœ… CHECKLIST DE PRÃ‰PARATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    checklist_items = []\n",
    "    \n",
    "    # 1. PrÃ©sence des donnÃ©es\n",
    "    if data_info is not None:\n",
    "        checklist_items.append((\"âœ…\", \"Dossiers de donnÃ©es crÃ©Ã©s\"))\n",
    "        \n",
    "        # VÃ©rifier chaque membre\n",
    "        for i in range(1, 4):\n",
    "            member_key = f'member{i}'\n",
    "            if member_key in data_info:\n",
    "                num_images = data_info[member_key]['num_images']\n",
    "                if num_images > 0:\n",
    "                    checklist_items.append((\"âœ…\", f\"Images pour {member_key}: {num_images} fichiers\"))\n",
    "                else:\n",
    "                    checklist_items.append((\"âŒ\", f\"Aucune image pour {member_key}\"))\n",
    "            else:\n",
    "                checklist_items.append((\"âŒ\", f\"Dossier {member_key} manquant\"))\n",
    "    else:\n",
    "        checklist_items.append((\"âŒ\", \"Dossiers de donnÃ©es manquants\"))\n",
    "    \n",
    "    # 2. QualitÃ© des donnÃ©es\n",
    "    if df_analysis is not None:\n",
    "        # VÃ©rifier les formats\n",
    "        formats = df_analysis['format'].unique()\n",
    "        supported_formats = {'JPEG', 'PNG', 'JPG'}\n",
    "        if all(fmt in supported_formats for fmt in formats):\n",
    "            checklist_items.append((\"âœ…\", f\"Formats d'images supportÃ©s: {', '.join(formats)}\"))\n",
    "        else:\n",
    "            checklist_items.append((\"âš ï¸\", f\"Formats mixtes dÃ©tectÃ©s: {', '.join(formats)}\"))\n",
    "        \n",
    "        # VÃ©rifier les tailles\n",
    "        min_size = df_analysis[['width', 'height']].min().min()\n",
    "        if min_size >= 224:\n",
    "            checklist_items.append((\"âœ…\", f\"RÃ©solution suffisante (min: {min_size}px)\"))\n",
    "        else:\n",
    "            checklist_items.append((\"âš ï¸\", f\"RÃ©solution faible dÃ©tectÃ©e (min: {min_size}px)\"))\n",
    "    else:\n",
    "        checklist_items.append((\"âŒ\", \"Analyse de qualitÃ© non effectuÃ©e\"))\n",
    "    \n",
    "    # 3. Ã‰tapes suivantes\n",
    "    next_steps = [\n",
    "        (\"ğŸ“\", \"Preprocessing des images (redimensionnement, normalisation)\"),\n",
    "        (\"ğŸ”„\", \"Augmentation des donnÃ©es si nÃ©cessaire\"),\n",
    "        (\"ğŸ”€\", \"Division des donnÃ©es pour l'apprentissage fÃ©dÃ©rÃ©\"),\n",
    "        (\"ğŸ§ \", \"Construction et test du modÃ¨le CNN\"),\n",
    "        (\"ğŸ”—\", \"ImplÃ©mentation de l'apprentissage fÃ©dÃ©rÃ©\"),\n",
    "        (\"ğŸ”\", \"Application des techniques d'explicabilitÃ©\"),\n",
    "        (\"ğŸ”’\", \"Test des mesures de confidentialitÃ©\")\n",
    "    ]\n",
    "    \n",
    "    # Affichage\n",
    "    print(\"\\nğŸ“Š Ã‰tat actuel:\")\n",
    "    for status, item in checklist_items:\n",
    "        print(f\"   {status} {item}\")\n",
    "    \n",
    "    print(\"\\nğŸš€ Prochaines Ã©tapes:\")\n",
    "    for status, step in next_steps:\n",
    "        print(f\"   {status} {step}\")\n",
    "    \n",
    "    # Recommandations finales\n",
    "    print(\"\\nğŸ’¡ Recommandations avant de continuer:\")\n",
    "    if data_info is None:\n",
    "        print(\"   1. ğŸ“¸ Collectez au moins 20-30 photos par membre\")\n",
    "        print(\"   2. ğŸ“ Organisez les photos dans data/raw/member1/, member2/, member3/\")\n",
    "        print(\"   3. ğŸ–¼ï¸ Assurez-vous que les photos sont de bonne qualitÃ©\")\n",
    "    else:\n",
    "        total_images = sum([info['num_images'] for info in data_info.values()])\n",
    "        if total_images < 60:\n",
    "            print(\"   1. ğŸ“¸ Collectez plus de photos (recommandÃ©: 20+ par membre)\")\n",
    "        print(\"   2. ğŸ” VÃ©rifiez la qualitÃ© et la diversitÃ© des photos\")\n",
    "        print(\"   3. â–¶ï¸ ProcÃ©dez au preprocessing (notebook 02)\")\n",
    "\n",
    "# CrÃ©er la checklist\n",
    "create_preparation_checklist(data_info, df_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35ff23",
   "metadata": {},
   "source": [
    "## ğŸ¯ Conclusion\n",
    "\n",
    "Cette exploration nous a permis de:\n",
    "\n",
    "1. **ğŸ“ Structure des donnÃ©es**: VÃ©rification de l'organisation des dossiers\n",
    "2. **ğŸ“Š Statistiques**: Analyse de la distribution et qualitÃ© des images\n",
    "3. **ğŸ” QualitÃ©**: Ã‰valuation des dimensions, formats et tailles\n",
    "4. **ğŸ”’ PrÃ©paration FL**: Analyse pour l'apprentissage fÃ©dÃ©rÃ©\n",
    "5. **âœ… Checklist**: Validation de l'Ã©tat de prÃ©paration\n",
    "\n",
    "### ğŸš€ Prochaines Ã©tapes\n",
    "\n",
    "1. **Notebook 02**: Preprocessing et augmentation des donnÃ©es\n",
    "2. **Notebook 03**: EntraÃ®nement du modÃ¨le CNN\n",
    "3. **Notebook 04**: ImplÃ©mentation de l'apprentissage fÃ©dÃ©rÃ©\n",
    "4. **Notebook 05**: Techniques d'explicabilitÃ© (LIME, SHAP, Grad-CAM)\n",
    "5. **Notebook 06**: Ã‰valuation de la confidentialitÃ© et sÃ©curitÃ©\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“ Note**: Ce notebook fait partie du projet Trustworthy AI pour la classification faciale Ã©thique avec apprentissage fÃ©dÃ©rÃ©."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
